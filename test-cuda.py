import torch

def test_cuda():
    print("ðŸ”¥ PyTorch version:", torch.__version__)
    print("ðŸ§  CUDA Available:", torch.cuda.is_available())
    
    if torch.cuda.is_available():
        print("ðŸŽ® GPU Name:", torch.cuda.get_device_name(0))
        print("ðŸ’¾ Memory Allocated (MB):", torch.cuda.memory_allocated() / 1024 / 1024)
        print("ðŸ§¹ Memory Reserved (MB):", torch.cuda.memory_reserved() / 1024 / 1024)
    else:
        print("ðŸ˜­ CUDA nggak tersedia, periksa lagi instalasi kamu!")

if __name__ == "__main__":
    test_cuda()
